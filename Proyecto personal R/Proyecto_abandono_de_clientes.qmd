---
title: ""
lag: es
format: 
  pdf:
    documentclass: article
    fontsize: 12pt
    linestretch: 1.5
    geometry: "margin=1in"
    number-sections: false
    colorlinks: true
    linkcolor: blue
    citecolor: blue
    urlcolor: blue
    filecolor: blue
mainfont: Times New Roman
monofont: Courier New
editor: visual
editor_options: 
  chunk_output_type: console

execute:
  echo: false       # Muestra el c√≥digo en los chunks
  warning: false   # Oculta advertencias
  message: false   # Oculta mensajes (ej. de librer√≠as)
  eval: true       # Ejecuta los chunks
  cache: true 
---

\thispagestyle{empty}
\vspace*{\fill}
\begin{center}
{\scshape\huge {Modelo Predictivo de Abandono de Clientes en el Sector de Telecomunicaciones usando Machine Learning en R}  \par\vspace{2cm}}
{\itshape\Large Trabajo Personal \par}
\vfill
{\Large Autor: \par}
{\large Juan Gabriel Carvajal Negrete \par\vspace{2cm}}
\vfill
\end{center}
\vspace*{\fill}

\newpage

```{r}
#| echo: false
#| warning: false
#| message: false

# Paquetes a usar 
require(magrittr)  # pip
require(tidyverse) # Manipulaci√≥n de datos 
require(ggplot2)   # Gr√°ficos 
require(psych)     # tablas (headtail)
library(stargazer) # c√≥digo l√°tex de las tablas 
require(xtable)    # c√≥digo l√°tex de las tablas 
library(caret)     # Separaci√≥n de datos 
library(pROC)
library(randomForest)
library(xgboost)
```

# Informaci√≥n basica de la base de datos

### Contexto de la base de datos

Predecir el comportamiento para fidelizar a los clientes. Puede analizar todos los datos relevantes de los clientes y desarrollar programas de fidelizaci√≥n espec√≠ficos. \[Conjuntos de datos de muestra de IBM\].Cada fila representa un cliente, cada columna contiene los atributos del cliente descritos en la columna Metadatos.

```{r}
#| echo: false
datos <- read.csv("WA_Fn-UseC_-Telco-Customer-Churn.csv", header = TRUE, sep = ",")
```

La base de datos cuenta con **`r dim(datos)`** filas y columnas respectivamente,los nombres de las variables de la base de datos son **`r names(datos)`**, el conjunto de datos incluye informaci√≥n sobre:

\- Clientes que se fueron en el √∫ltimo mes: la columna se llama **Churn** (Variable objetivo)\newline - Servicios a los que se ha suscrito cada cliente: tel√©fono, l√≠neas m√∫ltiples, Internet, seguridad en l√≠nea, copia de seguridad en l√≠nea, protecci√≥n de dispositivos, soporte t√©cnico y transmisi√≥n de TV y pel√≠culas.\newline - Informaci√≥n de la cuenta del cliente: cu√°nto tiempo ha sido cliente, contrato, m√©todo de pago, facturaci√≥n electr√≥nica, cargos mensuales y cargos totales\newline - Informaci√≥n demogr√°fica sobre los clientes: g√©nero, rango de edad y si tienen parejas y dependientes.

Estas son algunas observaciones b√°sicas de la base de datos ahora continuaremos e iremos mas afondo con nuestro datos, mostrando que tan completas est√°n nuestras variables y la importancia que tendr√° cada una de ellas en nuestros futuros modelos.

[La base de datos la puedes encontrar dando click aqu√≠](https://www.kaggle.com/datasets/blastchar/telco-customer-churn?resource=download) \newpage

# Descripci√≥n General y Estad√≠sticas Iniciales de la Base de Datos

```{r}
#| output: false

resumen1 <- data.frame(variables = names(datos),
completos = apply(!is.na(datos),2,sum)) %>% 
  mutate(porcentaje_completo = round(completos/nrow(datos)*100,2))

rownames(resumen1) <- NULL

resumen1 <- resumen1[c("variables","porcentaje_completo")]
```

\begin{table}[ht]
\centering
\caption{Porcentaje de completitud de las variables}
\begin{tabular}{|c|l|c|}
\hline
\textbf{N¬∞} & \textbf{Variable} & \textbf{Porcentaje Completo (\%)} \\
\hline
1  & customerID        & 100.00 \\
2  & gender            & 100.00 \\
3  & SeniorCitizen     & 100.00 \\
4  & Partner           & 100.00 \\
5  & Dependents        & 100.00 \\
6  & tenure            & 100.00 \\
7  & PhoneService      & 100.00 \\
8  & MultipleLines     & 100.00 \\
9  & InternetService   & 100.00 \\
10 & OnlineSecurity    & 100.00 \\
11 & OnlineBackup      & 100.00 \\
12 & DeviceProtection  & 100.00 \\
13 & TechSupport       & 100.00 \\
14 & StreamingTV       & 100.00 \\
15 & StreamingMovies   & 100.00 \\
16 & Contract          & 100.00 \\
17 & PaperlessBilling  & 100.00 \\
18 & PaymentMethod     & 100.00 \\
19 & MonthlyCharges    & 100.00 \\
20 & TotalCharges      &  99.84 \\
21 & Churn             & 100.00 \\
\hline
\end{tabular}
\end{table}

```{r}
# üîπ Gr√°fica de % de completitud por variable
ggplot(resumen1, aes(x = reorder(variables, porcentaje_completo), 
                    y = porcentaje_completo)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Completitud de la base de datos",
       x = "Variable",
       y = "% de valores completos") +
  theme_minimal()+
    theme(
    plot.title = element_text(hjust = 0.5),   # centra el t√≠tulo
    axis.title.x = element_text(hjust = 0.5), # centra t√≠tulo eje X
    axis.title.y = element_text(hjust = 0.5)  # centra t√≠tulo eje Y
  )

datos <- na.omit(datos)
```

\newpage

De acuerdo con la tabla y el gr√°fico presentados, la base de datos refleja un alto nivel de completitud, con un porcentaje m√≠nimo de valores faltantes. Esta condici√≥n es favorable, ya que garantiza una mayor confiabilidad en los resultados posteriores y disminuye la necesidad de aplicar t√©cnicas de imputaci√≥n o eliminaci√≥n de observaciones.

Con esta base s√≥lida, es posible avanzar hacia el an√°lisis exploratorio de cada una de las variables, lo cual permitir√° detectar posibles anomal√≠as, patrones inusuales o inconsistencias en los registros. Asimismo, resulta fundamental revisar que el tipo de dato asignado a cada variable corresponda efectivamente con su naturaleza, asegurando que la base se encuentre correctamente estructurada para el modelado y el an√°lisis estad√≠stico posterior.

# An√°lisis individual de las variables

```{r}
# convertir cada variable de tipo character a tipo factor 
# Gender
datos$SeniorCitizen <- as.character(datos$SeniorCitizen)
datos$gender <- recode(datos$gender,"Female"="1",
                       "Male"="0")
# reemplazar valores dentro de cada variable
# MultipleLines
datos$MultipleLines <- recode(datos$MultipleLines,"No phone service"="No") 
# OnlineSecurity
datos$OnlineSecurity <- recode(datos$OnlineSecurity,"No internet service"="No")
# OnlineBackup
datos$OnlineBackup <- recode(datos$OnlineBackup,"No internet service"="No")
# DeviceProtection
datos$DeviceProtection <- recode(datos$DeviceProtection,"No internet service"="No")
# TechSupport
datos$TechSupport <- recode(datos$TechSupport,"No internet service"="No")
# StreamingTV
datos$StreamingTV <- recode(datos$StreamingTV,"No internet service"="No")
# StreamingMovies
datos$StreamingMovies <- recode(datos$StreamingMovies,"No internet service"="No")

# Convertir en factor todas las variables de tipo character 
datos %<>% mutate(across(where(is.character),as.factor))

datos %<>% mutate(across(where(~is.factor(.) && all(levels(.) %in% c("Yes","No"))),
                        ~ ifelse(.=="Yes","1","0")))
datos %<>% mutate(across(where(is.character),as.factor))


# variables con tipo de datos y valores √∫nicos corregidos
# data.frame(variables = c(names(datos)),
#           tipo = sapply(datos,class),row.names = NULL) %>% xtable()

```

\begin{table}[ht]
\centering
\caption{Tipos de variables en el dataset}
\begin{tabular}{|r|l|l|}
  \hline
  & \textbf{Variables} & \textbf{Tipo} \\ 
  \hline
1 & customerID & factor \\ 
2 & gender & factor \\ 
3 & SeniorCitizen & factor \\ 
4 & Partner & factor \\ 
5 & Dependents & factor \\ 
6 & tenure & integer \\ 
7 & PhoneService & factor \\ 
8 & MultipleLines & factor \\ 
9 & InternetService & factor \\ 
10 & OnlineSecurity & factor \\ 
11 & OnlineBackup & factor \\ 
12 & DeviceProtection & factor \\ 
13 & TechSupport & factor \\ 
14 & StreamingTV & factor \\ 
15 & StreamingMovies & factor \\ 
16 & Contract & factor \\ 
17 & PaperlessBilling & factor \\ 
18 & PaymentMethod & factor \\ 
19 & MonthlyCharges & numeric \\ 
20 & TotalCharges & numeric \\ 
21 & Churn & factor \\ 
  \hline
\end{tabular}
\end{table}

\newpage

Luego de realizar un an√°lisis detallado de cada variable pudimos identificar que la mayor√≠a de ellas el programa las reconoc√≠a como variables **character** cuando en realidad deb√≠an ser consideradas como tipo **factor**, ademas tambi√©n pudimos identificar errores en la digitaci√≥n de la informaci√≥n.

# Gr√°ficas descriptivas individuales

```{r}
#| fig.show: hold
#| layout-ncol: 3
#| layout-nrow: 3
#| fig.align: center
#| fig.width: 6
#| fig.height: 4

# A Graficar en la siguiente pagina 

for (i in names(select(datos,-c("Churn","TotalCharges","MonthlyCharges","tenure","customerID",
  "StreamingMovies","StreamingTV","TechSupport",
  "DeviceProtection")))){
  print(
  datos %>%  ggplot(aes(x=.data[[i]],fill = Churn))+ 
    geom_bar(position = "dodge")+
    labs(title = paste("Distribici√≥n de",i,"seg√∫n Churn"),
         x=i,y="Numero de clientes")+
    scale_fill_brewer(palette = "Set2") +
    geom_text(stat = "count", aes(label = ..count..),
              position = position_dodge(width = 0.9), 
              vjust = -0.3, size = 3) +
    theme_minimal()+
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 14)  # centrado
    )
  )
}
```

\newpage

```{r}
#| fig.show: hold
#| layout-ncol: 3
#| layout-nrow: 3
#| fig.align: center
#| fig.width: 6
#| fig.height: 4


for (i in c("StreamingMovies","StreamingTV",
  "TechSupport","DeviceProtection")){
  print(
  datos %>%  ggplot(aes(x=.data[[i]],fill = Churn))+ 
    geom_bar(position = "dodge")+
    labs(title = paste("Distribici√≥n de",i,"seg√∫n Churn"),
         x=i,y="Numero de clientes")+
    scale_fill_brewer(palette = "Set2") +
    geom_text(stat = "count", aes(label = ..count..),
              position = position_dodge(width = 0.9), 
              vjust = -0.3, size = 3) +
    theme_minimal()+
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold", size = 14)  # centrado
    )
  )
}
```

```{r}
#| fig.width: 10
#| fig.height: 3.8

for (i in c("tenure","MonthlyCharges","TotalCharges")){
  if (i == "TotalCharges"){
    print(
      datos %>%
        mutate(intervalo = cut(.data[[i]]/10, breaks = 10)) %>%        # Divide tenure en 10 intervalos
        group_by(intervalo, Churn) %>%
        summarise(Frecuencia = n()) %>%
        ggplot(aes(x = intervalo, y = Frecuencia, fill = Churn)) +
        geom_col(position = "dodge", color = "white") +          # Barras separadas
        geom_text(aes(label = Frecuencia),
                  position = position_dodge(width = 0.9),
                  vjust = -0.3, size = 3.5) +                    # Texto encima de barras
        scale_fill_brewer(palette = "Set2") +
        labs(title = paste("Distribuci√≥n de la Variable",i,"por Churn"),
             x = paste(i,"(en intervalos)"),
             y = "Numero de clientes") +
        theme_minimal() +
        theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
    )
  }else{
  print(
    datos %>%
      mutate(intervalo = cut(.data[[i]], breaks = 10)) %>%        # Divide tenure en 10 intervalos
      group_by(intervalo, Churn) %>%
      summarise(Frecuencia = n()) %>%
      ggplot(aes(x = intervalo, y = Frecuencia, fill = Churn)) +
      geom_col(position = "dodge", color = "white") +          # Barras separadas
      geom_text(aes(label = Frecuencia),
                position = position_dodge(width = 0.9),
                vjust = -0.3, size = 3.5) +                    # Texto encima de barras
      scale_fill_brewer(palette = "Set2") +
      labs(title = paste("Distribuci√≥n de la Variable",i,"por Churn"),
           x = paste(i,"en intervalos"),
           y = "Numero de clientes") +
      theme_minimal() +
      theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))

      )
  }  
}
```

\vspace{0.7cm}

```{r}
#| fig.show: hold
#| layout-ncol: 2

for (i in c("MonthlyCharges","TotalCharges")){
  print(
    datos %>%
  ggplot(aes(x = .data[[i]], fill = Churn)) +
  geom_density(alpha = 0.5) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = paste("Distribuci√≥n de",i,"por Estado de Churn"),
       x = paste(i),
       y = "Densidad") +
  xlim(0,120)+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
    
  )
  
}
```

Las gr√°ficas anteriores muestran la cantidad de clientes que han abandonado el servicio y las personas que han permanecido con el en las diferentes variables de tipo factor que se tienen en la base de datos, ademas tambi√©n presentamos gr√°ficas con variables num√©ricas tomadas en intervalos para seguir observando el comportamiento de los cientes, una observaci√≥n general es que son mas los clientes que deciden continuar con el servicio que los que deciden dejarlo. por ultimo revisemos un gr√°fico de densidad para las variables mas num√©ricas de nuestro dataset.

\vspace{0.7cm}

\newpage

# Modelaci√≥n (Datos supervisados)

### Modelo de regresi√≥n log√≠stico.

El primer modelo que se va a implementar en este proyecto es el modelo de regresi√≥n log√≠stica aplicando el m√©todo de selecci√≥n stepwise (paso a paso) y esto fueron los resultados que se obtuvieron.

```{r}
#| cache: true
#| comment: ""

trainIndex <- createDataPartition(datos$Churn, p = 0.8, list = FALSE)
train <- datos[trainIndex, ]
test <- datos[-trainIndex, ]

# Modelo creado y guardado en el script Borrador de este proyecto.
modelo_step <- readRDS("modelo_step.rds")
# summary(modelo_step)$coefficients
```

\begin{table}[H]
\centering
\caption{\textbf{Resumen de coeficientes del modelo log√≠stico reducido}}
\renewcommand{\arraystretch}{0.8} % m√°s espacio entre filas
\setlength{\tabcolsep}{8pt} % m√°s espacio entre columnas
\begin{tabular}{|l|r|r|r|r|}
\hline
\textbf{Variable} & \textbf{Estimate} & \textbf{Std. Error} & \textbf{z value} & \textbf{Pr($>$$|$z$|$)} \\ 
\hline
(Intercept) & 2.12 & 0.40 & 5.34 & 0.00 \\ 
SeniorCitizen1 & 0.26 & 0.09 & 2.80 & 0.01 \\ 
tenure & -0.06 & 0.01 & -8.78 & 0.00 \\ 
PhoneService1 & 1.01 & 0.30 & 3.43 & 0.00 \\ 
MultipleLines1 & 0.62 & 0.11 & 5.85 & 0.00 \\ 
InternetServiceFiber optic & 2.79 & 0.31 & 8.90 & 0.00 \\ 
InternetServiceNo & -2.81 & 0.38 & -7.34 & 0.00 \\ 
OnlineBackup1 & 0.28 & 0.11 & 2.64 & 0.01 \\ 
DeviceProtection1 & 0.40 & 0.11 & 3.64 & 0.00 \\ 
StreamingTV1 & 1.04 & 0.16 & 6.69 & 0.00 \\ 
StreamingMovies1 & 0.92 & 0.15 & 5.94 & 0.00 \\ 
ContractOne year & -0.74 & 0.12 & -6.14 & 0.00 \\ 
ContractTwo year & -1.33 & 0.20 & -6.74 & 0.00 \\ 
PaperlessBilling1 & 0.36 & 0.08 & 4.33 & 0.00 \\ 
PaymentMethodCredit card (automatic) & -0.07 & 0.13 & -0.52 & 0.60 \\ 
PaymentMethodElectronic check & 0.28 & 0.11 & 2.59 & 0.01 \\ 
PaymentMethodMailed check & -0.08 & 0.13 & -0.60 & 0.55 \\ 
MonthlyCharges & -0.08 & 0.01 & -6.39 & 0.00 \\ 
TotalCharges & 0.00 & 0.00 & 3.98 & 0.00 \\ 
\hline
\end{tabular}
\end{table}

```{r}
# Predicciones en probabilidad
pred_probs <- predict(modelo_step, newdata = test, type = "response")

# Convertir a clases
pred_class <- ifelse(pred_probs > 0.5, "1", "0")
pred_class <- as.factor(pred_class)

# Matriz de confusi√≥n
conf_matrix <- confusionMatrix(pred_class, test$Churn, positive = "1")
conf_matrix$table

cat("La precision con la que el modelo acierta es de ",conf_matrix$overall["Accuracy"])
```

```{r}
#| fig.width: 5
#| fig.height: 3.8
#| fig.align: center

roc_obj <- roc(test$Churn, pred_probs)

roc_df <- data.frame(
  FPR = 1 - roc_obj$specificities,
  TPR = roc_obj$sensitivities
)

# Valor del AUC
auc_value <- round(auc(roc_obj), 3)

# Crear una columna para el valor de la l√≠nea diagonal
roc_df$random_line <- roc_df$FPR

# Gr√°fico
ggplot(roc_df, aes(x = FPR, y = TPR)) +
  # sombreado entre la curva y la l√≠nea diagonal
  geom_ribbon(aes(ymin = random_line, ymax = TPR),
              fill = "#0072B2", alpha = 0.25) +
  # l√≠nea ROC
  geom_line(color = "#0072B2", size = 1.2) +
  # l√≠nea diagonal de referencia
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray60") +
  labs(
    title = "Curva ROC - Modelo de Regresi√≥n Log√≠stica",
    subtitle = paste("√Årea bajo la curva (AUC):", auc_value),
    x = "1 - Especificidad (False Positive Rate)",
    y = "Sensibilidad (True Positive Rate)"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, face = "italic", color = "gray40"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray85"),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(color = "gray30")
  )
```

### Modelo de Random Forest.

```{r}

modelo_rf <- readRDS("modelo_rf.rds")

conf_matrix_rf <- readRDS("conf_matrix_rf.rds")

conf_matrix_rf$table
cat("La precision con la que el modelo acierta es de",conf_matrix_rf$overall["Accuracy"])
```

\vspace{0.7cm}

Hasta este punto ambos modelos dan un precisi√≥n casi igual, no se evidencia una mejora en el modelo de **Random Forest** pero, haremos un an√°lisis de las variables e intentaremos mejorar mas las predicciones de nuestro modelo.

\newpage

### Visualizaci√≥n de importancia relativa de cada variable del modelo

```{r}
#| fig.width: 7
#| fig.height: 6
#| fig.align: center
 
varImpPlot(modelo_rf,
           main = "Importancia de las Variables - Random Forest",
           col = "#1B9E77")
```

Entonces las variables que vamos a considerar dejar en el modelo son TotalCharges, MonthlyCharges,tenure,Contract, InternetService, PaymentMethod,PaperlessBilling  TechSupport, OnlineSecurity, PaperlessBilling, PaymentMethod, OnlineBackup, StreamingTV.

\newpage

```{r}
modelo_rf_reducido <- readRDS("modelo_rf_reducido.rds")
conf_matrix_rf_reducido <- readRDS("conf_matrix_rf_reducido.rds")

conf_matrix_rf_reducido$table
cat("La precision con la que el modelo acierta es   de",conf_matrix_rf_reducido$overall["Accuracy"])
```

\vspace{1cm}

```{r}
g <- readRDS("g.rds")
g
```


### Modelo XGBOOST

```{r}
modelo_xgb_tuned <- readRDS("modelo_xgb_tuned.rds")
plot(modelo_xgb_tuned)

conf_matrix_xg <- readRDS("conf_matrix_xg.rds")

conf_matrix_xg$table

cat("La precision con la que el modelo acierta es   de",conf_matrix_xg$overall["Accuracy"])
```

```{r}
g1 <- readRDS("g1.rds")
g1
```

### Conclusion 

Tras la comparaci√≥n de los tres modelos de clasificaci√≥n ‚ÄîRegresi√≥n Log√≠stica, Random Forest y XGBoost‚Äî se observ√≥ que todos presentan un desempe√±o similar en t√©rminos de m√©tricas de evaluaci√≥n (AUC, precisi√≥n, recall y matriz de confusi√≥n).

Si bien el modelo XGBoost obtuvo el mejor rendimiento, superando ligeramente a los otros dos, la diferencia fue m√≠nima, lo que indica que los tres algoritmos logran capturar de forma consistente los patrones de abandono (churn) presentes en los datos.

Esto sugiere que el conjunto de variables utilizadas tiene un poder predictivo estable, y que la mejora de la precisi√≥n podr√≠a depender m√°s del ajuste fino de hiperpar√°metros o de la incorporaci√≥n de nuevas variables (por ejemplo, variables de comportamiento o uso del servicio) que del tipo de modelo en s√≠.
